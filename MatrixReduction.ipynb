{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f243fb99-810c-46f2-8d1c-419c8cecf606",
   "metadata": {},
   "source": [
    "The transfer function for the causal LTI system with a realization $(A, B, C, D)$ is given by\n",
    "\\begin{equation*}\n",
    "    H(s) = C(sI_{n} - A)^{-1}B.\n",
    "\\end{equation*}\n",
    "Notice that $H(s) = Cv(s)$, where $v(s)$ is the solution of a parametrized linear coercive model\n",
    "\\begin{equation}\n",
    "    a(v, w; s) = l(w),\n",
    "\\end{equation}\n",
    "where $a(v, w; s) = w^{*}(sI_{n} - A)v$ and $l(w) = w^{*}B$. In other words, we replace the matrix computation of $(sI_{n} - A)^{-1}B$ with a parametrized model (1). However, if one wants to apply this to the Iterative rational Krylov algorithm (IRKA), then the following matrix computations must be done to construct the projection matrices $V$ and $W$:\n",
    "\\begin{equation*}\n",
    "    (-\\mu_{i}I_{n} - A)^{-1}B\\hat{b}_{i}, \\quad \\text{and} \\quad (-\\mu_{i}I_{n} - A)^{-*}C^{T}\\hat{c}_{i} \\quad \\text{for } i = 1,\\ldots,r,\n",
    "\\end{equation*}\n",
    "where $-\\mu_{i}, \\hat{c}_{i}, \\hat{b}_{i}$ are some initial interpolation data and $0 < r \\leq n$ is the desired order of approximating ROM. So, we have decided to solve two parametrized linear coercive models to construct projection matrices $V$ and $W$:\n",
    "\\begin{equation}\n",
    "    a_{1}(v_{1}, w; s) = l_{1}(w) \\quad \\text{and} \\quad a_{2}(v_{2}, w; s) = l_{2}(w),\n",
    "\\end{equation}\n",
    "where $a_{1}(v_{1}, w; s) = w^{*}(sI_{n} - A)v_{1}$ and $l_{1}(w) = w^{*}B$, and $a_{2}(v_{2}, w; s) = w^{*}(sI_{n} - A)^{*}v_{2}$ and $l_{2}(w) = w^{*}C^{T}$, and solutions to these parametrized linear coercive models are\n",
    "\\begin{equation*}\n",
    "    v_{1}(s) = (sI_{n} - A)^{-1}B \\quad \\text{and} \\quad v_{2}(s) = (sI_{n} - A)^{-*}C^{T}.\n",
    "\\end{equation*}\n",
    "Therefore, knowing $v_{1}(\\mu_{i})$ and $v_{2}(\\mu_{i})$ for $i = 1, \\ldots, r$ will suffice for constructing the projection matrices $V$ and $W$. Also, note that these two FOMs are parameter-separable, i.e.,\n",
    "\\begin{equation*}\n",
    "    a_{1}(v_{1},w;s) = w^{*}(sI_{n} - A)v_{1} = sw^{*}I_{n}v_{1} - w^{*}Av_{1}  \\quad  a_{2}(v_{2},w;s) = w^{*}(sI_{n} - A)^{*}v_{2} = \\overline{s}w^{*}I_{n}v_{2} - w^{*}A^{*}v_{2}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d1bcb5-cc0e-4fea-857a-a99f7cb1031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "from numpy.linalg import inv\n",
    "from pymor.basic import *\n",
    "from pymor.models.basic import StationaryModel\n",
    "from pymor.operators.constructions import LincombOperator\n",
    "from pymor.operators.numpy import NumpyMatrixOperator\n",
    "from pymor.parameters.functionals import ProjectionParameterFunctional\n",
    "from pymor.vectorarrays.numpy import NumpyVectorSpace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6592df60-f621-4eb5-a723-c180b2ba1879",
   "metadata": {},
   "source": [
    "### Constructing a stationary model\n",
    "Let us construct a stationary model of the following parametrized linear coercive model using `pyMOR`:\n",
    "\\begin{equation}\n",
    "    a(v, w; s) = l(w),\n",
    "\\end{equation}\n",
    "where $a(v, w; s) = w^{*}(sI_{n} - A)v$ and $l(w) = w^{*}B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e5a5d02-f4fb-4418-9e71-25a089a3ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatrixModel(A, B, dim: int):\n",
    "\n",
    "    '''\n",
    "    This function create a stationary model of the following linear coercive model derived for the given two matrices A and B:\n",
    "    \n",
    "        a(v, w; s) =w^{*}(sI_{n} - A)v and l(w) = w^{*}B.\n",
    "    '''\n",
    "    \n",
    "    # Create Numpy vector space\n",
    "    vector_space = NumpyVectorSpace(dim)\n",
    "\n",
    "    # Define NumpyMatrixOperators\n",
    "    I_op = NumpyMatrixOperator(np.eye(dim))\n",
    "\n",
    "    if isinstance(A, np.ndarray) and isinstance(B, np.ndarray):\n",
    "        A_op = NumpyMatrixOperator(A)\n",
    "        B_op = NumpyMatrixOperator(B.reshape(-1, 1))\n",
    "    else:\n",
    "        A_op = A\n",
    "        B_op = B       \n",
    "\n",
    "    # Define parameter functional for 's'\n",
    "    s_param = ProjectionParameterFunctional('s', 1)\n",
    "\n",
    "    # Define bilinear form a(v, w; s) = w^* (sI - A)v\n",
    "    a_op = LincombOperator([I_op, A_op], [s_param, -1])\n",
    "\n",
    "    # Define linear functional l(w) = w^*B\n",
    "    l_op = B_op\n",
    "\n",
    "    # Define the StationaryModel\n",
    "    model = StationaryModel(operator = a_op, rhs = l_op)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2815a64-3885-48f9-ba8c-ac4d582a96b2",
   "metadata": {},
   "source": [
    "### Examples\n",
    "Notice that to make this process more convenient, we provide two options for input matrices. If one has the matrices as `NumPy` arrays, they can import them directly without changing their type to work with `pyMOR`. Additionally, if one wants to input matrices from existing `pyMOR` models, this can also be done directly. To demonstrate this, we provide two examples: one with random matrices that we construct ourselves, and the other with matrices imported from the `penzl_example` in `pymor.models.examples`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a187f88-ab03-4c8b-af30-2cb5e9400190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StationaryModel(\n",
       "    LincombOperator(\n",
       "        (NumpyMatrixOperator(<20x20 dense>), NumpyMatrixOperator(<20x20 dense>)),\n",
       "        (ProjectionParameterFunctional('s', index=0), -1)),\n",
       "    NumpyMatrixOperator(<20x1 dense>),\n",
       "    output_functional=ZeroOperator(NumpyVectorSpace(0), NumpyVectorSpace(20)),\n",
       "    products={},\n",
       "    output_d_mu_use_adjoint=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stationary model constructed using random numpy arrays\n",
    "\n",
    "# Randomly generated arrays\n",
    "np.random.seed(127)\n",
    "matrixA = np.random.rand(20, 20)\n",
    "matrixB = B = np.random.rand(20)\n",
    "\n",
    "model_numpy = MatrixModel(A = matrixA, B = matrixB, dim = 20)\n",
    "model_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b936a0a6-c7ce-481f-acb3-2ab87e82799a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d474e47d868640b897da224e4498aa4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(HTML(value='', layout=Layout(height='16em', width='100%')),), titles=('Log Output',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution to the linear coercive model is \n",
      " [[ 1.10896524  1.96032033  0.02339715  0.52739001 -0.35238441 -1.85189312\n",
      "  -0.11570617 -0.4575037   0.55493919 -0.96350068  1.01490125  0.05632634\n",
      "   0.23435721 -0.72291187  0.47195613 -1.1582535  -0.48791287  0.20426283\n",
      "  -0.56944887 -0.30429143]].\n",
      "The exact value of the matrix computation (1.4I - A)^{-1}B is \n",
      " [[ 1.10896524  1.96032033  0.02339715  0.52739001 -0.35238441 -1.85189312\n",
      "  -0.11570617 -0.4575037   0.55493919 -0.96350068  1.01490125  0.05632634\n",
      "   0.23435721 -0.72291187  0.47195613 -1.1582535  -0.48791287  0.20426283\n",
      "  -0.56944887 -0.30429143]].\n",
      "The L-infinity error is 2.4424906541753444e-15.\n"
     ]
    }
   ],
   "source": [
    "# Set parameter for evaluation\n",
    "parameter = {'s': 1.4}  # s = 1.4\n",
    "\n",
    "# Solve the model\n",
    "solution = model_numpy.solve(parameter).to_numpy()\n",
    "\n",
    "# Exact matrix computation\n",
    "exact = (inv(parameter['s']*np.eye(20) - matrixA)@matrixB).reshape(1, 20)\n",
    "\n",
    "# A comparison between the model's result and the exact matrix computation\n",
    "print(f'The solution to the linear coercive model is \\n {solution}.')\n",
    "print(f'The exact value of the matrix computation ({parameter[\"s\"]}I - A)^{{-1}}B is \\n {exact}.')\n",
    "print(f'The L-infinity error is {np.max(abs(exact - solution))}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fedee36-5de9-41a0-b802-5df69b135ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StationaryModel(\n",
       "    LincombOperator(\n",
       "        (NumpyMatrixOperator(<1006x1006 dense>), NumpyMatrixOperator(<1006x1006 sparse, 1012 nnz>)),\n",
       "        (ProjectionParameterFunctional('s', index=0), -1)),\n",
       "    NumpyMatrixOperator(<1006x1 dense>),\n",
       "    output_functional=ZeroOperator(NumpyVectorSpace(0), NumpyVectorSpace(1006)),\n",
       "    products={},\n",
       "    output_d_mu_use_adjoint=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stationary model constructed using matrices obtained from penzl example\n",
    "from pymor.models.examples import penzl_example\n",
    "\n",
    "penzl = penzl_example()\n",
    "\n",
    "model_penzl = MatrixModel(penzl.A, penzl.B, dim = penzl.order)\n",
    "model_penzl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e89aa89f-bc33-474a-8676-0c8f844e48a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e9ee3c3ca94d72a6fadd98d605ec0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(HTML(value='', layout=Layout(height='16em', width='100%')),), titles=('Log Output',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution to the linear coercive model is \n",
      " [[ 0.10004002+2.00080032e-03j -0.10004002+2.00080032e-03j\n",
      "   0.050005  +5.00050005e-04j ...  0.001003  -2.01204612e-06j\n",
      "   0.001002  -2.00801600e-06j  0.001001  -2.00399798e-06j]].\n",
      "The exact value of the matrix computation ((-1+2j)I - A)^{-1}B is \n",
      " [[ 0.10004002+2.00080032e-03j -0.10004002+2.00080032e-03j\n",
      "   0.050005  +5.00050005e-04j ...  0.001003  -2.01204612e-06j\n",
      "   0.001002  -2.00801600e-06j  0.001001  -2.00399798e-06j]].\n",
      "The L-infinity error is 2.7755575615628914e-17.\n"
     ]
    }
   ],
   "source": [
    "from pymor.algorithms.to_matrix import to_matrix\n",
    "\n",
    "# Set parameter for evaluation\n",
    "parameter = {'s': -1 + 2*1j}  # s = - 1 + 2i\n",
    "\n",
    "# Solve the model\n",
    "solution = model_penzl.solve(parameter).to_numpy()\n",
    "\n",
    "# Exact matrix computation\n",
    "matrixA = to_matrix(penzl.A).toarray()\n",
    "matrixB = to_matrix(penzl.B)\n",
    "\n",
    "exact = (inv(parameter['s']*np.eye(penzl.order) - matrixA)@matrixB).reshape(1, penzl.order)\n",
    "\n",
    "# A comparison between the model's result and the exact matrix computation\n",
    "print(f'The solution to the linear coercive model is \\n {solution}.')\n",
    "print(f'The exact value of the matrix computation ({parameter[\"s\"]}I - A)^{{-1}}B is \\n {exact}.')\n",
    "print(f'The L-infinity error is {np.max(abs(exact - solution))}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4524c1-8f04-477e-ae98-8d0833a2d987",
   "metadata": {},
   "source": [
    "## Reduced Basis Methods\n",
    "\n",
    "As an example, we will use `penzl_example` from `pymor.models.examples` to construct a reduced basis using the reduced basis methods available in `pyMOR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7d507872-5ef7-45d3-bd79-b41e3d0cff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.models.examples import penzl_example\n",
    "\n",
    "penzl = penzl_example()\n",
    "model_penzl = MatrixModel(penzl.A, penzl.B, dim = penzl.order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698bffee-4de6-4e31-8a3f-52807cd936a1",
   "metadata": {},
   "source": [
    "### Proper Orthogonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d1790e6b-5614-4256-b6dc-af50775d4d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b38fb663c374d01ae6cd7ea688a71ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(HTML(value='', layout=Layout(height='16em', width='100%')),), titles=('Log Output',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An 1006 by 10 snapshot matrix is \n",
      " [[ 0.10109542  0.10187862  0.10121497 ...  0.10177499  0.10129963\n",
      "   0.10191404]\n",
      " [-0.09888003 -0.09804799 -0.09875476 ... -0.09815963 -0.09866567\n",
      "  -0.09800972]\n",
      " [ 0.05027541  0.05047437  0.05030567 ...  0.05044794  0.05032712\n",
      "   0.05048341]\n",
      " ...\n",
      " [ 0.0010019   0.00100109  0.00100177 ...  0.00100119  0.00100169\n",
      "   0.00100105]\n",
      " [ 0.00100089  0.00100008  0.00100077 ...  0.00100019  0.00100068\n",
      "   0.00100005]\n",
      " [ 0.00099989  0.00099908  0.00099977 ...  0.00099919  0.00099968\n",
      "   0.00099905]]\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter space\n",
    "parameter_space = model_penzl.parameters.space(0.0001, 1.)\n",
    "parameter_space\n",
    "\n",
    "# Define a training set\n",
    "training_set = parameter_space.sample_randomly(10)\n",
    "\n",
    "# Compute FOM solutions for the parameters in the training set\n",
    "solution_snapshots = model_penzl.solution_space.empty()\n",
    "for mu in training_set:\n",
    "    solution_snapshots.append(model_penzl.solve(mu))\n",
    "\n",
    "# Snapshot matrix S\n",
    "snapshot_matrix = solution_snapshots.to_numpy().T\n",
    "print(f'An {snapshot_matrix.shape[0]} by {snapshot_matrix.shape[1]} snapshot matrix is \\n {snapshot_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a7156f42-ddfa-408e-844d-d1d8d4c85c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reduced basis (containing the first 6 left singular vectors (POD modes) of the snapshot matrix as its columns) is \n",
      " [[-0.09912212 -0.18736895  0.24748348 -0.29943034  0.33694178 -0.36719748]\n",
      " [ 0.09626081  0.17403445 -0.20376072  0.18681599 -0.10719003 -0.03045406]\n",
      " [-0.04921171 -0.09207857  0.11858836 -0.13701396  0.14455083 -0.14769711]\n",
      " ...\n",
      " [-0.00097864 -0.00180737  0.00224931 -0.00241821  0.00223715 -0.00184414]\n",
      " [-0.00097766 -0.00180557  0.00224707 -0.00241584  0.00223502 -0.00184249]\n",
      " [-0.00097668 -0.00180377  0.00224485 -0.00241348  0.0022329  -0.00184084]]\n"
     ]
    }
   ],
   "source": [
    "# Finding the Singular Value Decomposition (SVD) of the snapshot matrix -> S = UΣV^T\n",
    "U, D, Vt = np.linalg.svd(snapshot_matrix, full_matrices = False) # using 'pod_basis, pod_singular_values = pod(solution_snapshots)' gives wrong result, that's why we don't use it here : pod_basis._len != 10 (5 != 10)\n",
    "\n",
    "# Activate below to automatically select the number of modes based on the energy criterion\n",
    "## The number of modes m should be chosen based on the energy criterion, which ensures that a sufficient portion of the system's total energy (or variance) is captured by the first m modes.\n",
    "#cumulative_energy = np.cumsum(D**2) / np.sum(D**2)\n",
    "\n",
    "##Select the number of modes m to capture at least 95% of the energy\n",
    "#threshold = 0.95  # 95% of the total energy\n",
    "#m = np.argmax(cumulative_energy >= threshold) + 1\n",
    "\n",
    "m = 6\n",
    "\n",
    "if m > min(snapshot_matrix.shape):\n",
    "    raise ValueError(\"m cannot exceed the rank of the snapshot matrix.\")\n",
    "\n",
    "# The reduced basis (POD basis)\n",
    "pod_basis = U[:,:m]\n",
    "print(f'The reduced basis (containing the first {m} left singular vectors (POD modes) of the snapshot matrix as its columns) is \\n {pod_basis}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
