{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the POD-Galerkin RB method for approximate transfer function evaluation to the IRKA framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following matrix computations must be done to construct the projection matrices $V$ and $W$ for the Iterative rational Krylov algorithm (IRKA):\n",
    "\\begin{equation*}\n",
    "    (-\\mu_{i}I_{n} - A)^{-1}B\\hat{b}_{i}, \\quad \\text{and} \\quad (-\\mu_{i}I_{n} - A)^{-*}C^{T}\\hat{c}_{i} \\quad \\text{for } i = 1,\\ldots,r,\n",
    "\\end{equation*}\n",
    "where $-\\mu_{i}, \\hat{c}_{i}, \\hat{b}_{i}$ are interpolation data and $0 < r \\leq n$ is the desired order of approximating ROM. \n",
    "\n",
    "So, we have decided to solve two parametrized linear coercive models to construct projection matrices $V$ and $W$:\n",
    "\\begin{equation}\n",
    "    a_{1}(v_{1}, w; s) = l_{1}(w) \\quad \\text{and} \\quad a_{2}(v_{2}, w; s) = l_{2}(w),\n",
    "\\end{equation}\n",
    "where $a_{1}(v_{1}, w; s) = w^{*}(sI_{n} - A)v_{1}$ and $l_{1}(w) = w^{*}B$, and $a_{2}(v_{2}, w; s) = w^{*}(sI_{n} - A)^{*}v_{2}$ and $l_{2}(w) = w^{*}C^{T}$, and solutions to these parametrized linear coercive models are\n",
    "\\begin{equation*}\n",
    "    v_{1}(s) = (sI_{n} - A)^{-1}B \\quad \\text{and} \\quad v_{2}(s) = (sI_{n} - A)^{-*}C^{T}.\n",
    "\\end{equation*}\n",
    "Therefore, knowing $v_{1}(\\mu_{i})$ and $v_{2}(\\mu_{i})$ for $i = 1, \\ldots, r$ will suffice for constructing the projection matrices $V$ and $W$. Also, note that these two FOMs are parameter-separable, i.e.,\n",
    "\\begin{equation*}\n",
    "    a_{1}(v_{1},w;s) = w^{*}(sI_{n} - A)v_{1} = sw^{*}I_{n}v_{1} - w^{*}Av_{1}  \\quad  a_{2}(v_{2},w;s) = w^{*}(sI_{n} - A)^{*}v_{2} = \\overline{s}w^{*}I_{n}v_{2} - w^{*}A^{*}v_{2}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pymor.basic import *\n",
    "from pymor.models.basic import StationaryModel\n",
    "from pymor.algorithms.to_matrix import to_matrix\n",
    "from pymor.vectorarrays.numpy import NumpyVectorSpace\n",
    "from pymor.operators.numpy import NumpyMatrixOperator\n",
    "from pymor.operators.constructions import LincombOperator\n",
    "from pymor.parameters.functionals import ProjectionParameterFunctional, ConjugateParameterFunctional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatrixModel(A, B, C):\n",
    "    \n",
    "    '''\n",
    "    Description\n",
    "    -----------\n",
    "    This function creates a StationaryModel for the following linear coercive models derived from the given three matrices A, B, and C:\n",
    "    \n",
    "        a_1(v, w; s) = w*(sI_n - A)v and l_1(w) = w*B\n",
    "        a_2(v, w; s) = w*(sI_n - A)*v and l_2(w) = w*C^T.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A: NumpyMatrixOperator or numpy.ndarray\n",
    "        A.shape = (n, n) or to_matrix(A).shape = (n, n)\n",
    "    B: NumpyMatrixOperator or numpy.ndarray\n",
    "        A.shape = (n, 1) or to_matrix(B).shape = (n, 1)\n",
    "    C: NumpyMatrixOperator or numpy.ndarray\n",
    "        A.shape = (1, n) or to_matrix(C).shape = (1, n)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    model_V: StationaryModel\n",
    "    model_W: StationaryModel\n",
    "    '''\n",
    "\n",
    "    # Define operators (and also a dimension of a model)\n",
    "    if isinstance(A, np.ndarray):\n",
    "        dim = A.shape[0]\n",
    "        A_op = NumpyMatrixOperator(A)\n",
    "    else:\n",
    "        dim = to_matrix(A).shape[0]\n",
    "        A_op = A\n",
    "\n",
    "    if isinstance(B, np.ndarray):\n",
    "        B_op = NumpyMatrixOperator(B) \n",
    "    else:\n",
    "        B_op = B  \n",
    "\n",
    "    if isinstance(C, np.ndarray):\n",
    "        C_op = NumpyMatrixOperator(C.T)  \n",
    "    else:\n",
    "        C_op = C.H  # C is real, so adjoint is transpose\n",
    "\n",
    "    I_op = NumpyMatrixOperator(np.eye(dim))\n",
    "    \n",
    "    # Define parameter functional for 's'\n",
    "    s_param = ProjectionParameterFunctional('s', 1)\n",
    "\n",
    "    # Define bilinear form a(v, w; s) = w*(sI - A)v\n",
    "    a_op_1 = LincombOperator([I_op, A_op], [s_param, -1])\n",
    "\n",
    "    # Define bilinear form a(v, w; s) = w*(sI - A)*v -> Note: (sI - A)* = s*I - A*\n",
    "    a_op_2 = LincombOperator([I_op, A_op.H], [ConjugateParameterFunctional(s_param), -1])\n",
    "    \n",
    "    # Define linear functional l(w) = w^*B\n",
    "    l_op_1 = B_op\n",
    "\n",
    "    # Define linear functional l(w) = w^*C^{T}\n",
    "    l_op_2 = C_op\n",
    "\n",
    "    # Define the StationaryModels\n",
    "    model_V = StationaryModel(operator=a_op_1, rhs=l_op_1)\n",
    "    model_W = StationaryModel(operator=a_op_2, rhs=l_op_2)\n",
    "\n",
    "    return [model_V, model_W] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatrixReductor(model_V, model_W, training_set, reduced_order_V: int, reduced_order_W: int):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "    ------------------------------------------------\n",
    "    model_V - Stationary Model of linear coercive model w*(sI_n - A)v = w*B -> StationaryModel\n",
    "    model_W - Stationary Model of linear coercive model w*(sI_n - A)*v -> StationaryModel\n",
    "    training_set - an array containing parameters used to construct the snapshot matrix -> type(training_set[i]) = pymor.parameters.base.Mu (list of Mu objects)\n",
    "    ------------------------------------------------\n",
    "    Outputs:\n",
    "    ------------------------------------------------\n",
    "    pod_rom_V\n",
    "    pod_rom_W\n",
    "    '''\n",
    "\n",
    "    # Compute FOM solutions for the parameters in the training set\n",
    "    solution_snapshots_V = model_V.solution_space.empty()\n",
    "    solution_snapshots_W = model_W.solution_space.empty()\n",
    "    for s in training_set:\n",
    "        solution_snapshots_V.append(model_V.solve(s))\n",
    "        solution_snapshots_W.append(model_W.solve(s))\n",
    "        \n",
    "    # Snapshot matrices\n",
    "    snapshot_matrix_V = solution_snapshots_V.to_numpy().T # Note: One may also use solution_snapshots_V.impl._array.T to get np.ndarray type needed for computation\n",
    "    snapshot_matrix_W = solution_snapshots_W.to_numpy().T\n",
    "\n",
    "    # Finding the Singular Value Decomposition (SVD) of snapshot matrices -> S = UÎ£V^T\n",
    "    U_V, D_V, Vt_V = np.linalg.svd(snapshot_matrix_V, full_matrices = True)\n",
    "    U_W, D_W, Vt_W = np.linalg.svd(snapshot_matrix_W, full_matrices = True)\n",
    "\n",
    "    if reduced_order_V > min(snapshot_matrix_V.shape):\n",
    "        raise ValueError(\"'reduced_order_V' cannot exceed the rank of the snapshot matrix.\")\n",
    "    if reduced_order_W > min(snapshot_matrix_W.shape):\n",
    "        raise ValueError(\"'reduced_order_W' cannot exceed the rank of the snapshot matrix.\")\n",
    "\n",
    "    # The reduced bases (POD bases)\n",
    "    pod_basis_numpy_V = U_V[:,:reduced_order_V]\n",
    "    pod_basis_numpy_W = U_W[:,:reduced_order_W]\n",
    "\n",
    "    # Convert NumPy array into VectorArray \n",
    "    space_V = NumpyVectorSpace(model_V.order) #number of columns = model_V.order\n",
    "    space_W = NumpyVectorSpace(model_W.order)\n",
    "    pod_basis_V = space_V.make_array(pod_basis_numpy_V.T) #This is actually transpose of POD-RB basis\n",
    "    pod_basis_W = space_W.make_array(pod_basis_numpy_W.T) #This is actually transpose of POD-RB basis\n",
    "    \n",
    "    # POD-Galerkin RB method\n",
    "    pod_reductor_V = StationaryRBReductor(model_V, RB = pod_basis_V) \n",
    "    pod_reductor_W = StationaryRBReductor(model_W, RB = pod_basis_W) \n",
    "    pod_rom_V = pod_reductor_V.reduce()\n",
    "    pod_rom_W = pod_reductor_W.reduce()\n",
    "\n",
    "    return [pod_rom_V, pod_reductor_V, pod_rom_W, pod_reductor_W]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $A\\in\\mathbb{R}^{n\\times n}$ $B\\in\\mathbb{R}^{n\\times 1}$ $C\\in\\mathbb{R}^{1\\times n}$ be given. The `ProjectionMatrices` function defined below includes `R_V = R^{V}_N(s)` and `R_W = R^{W}_M(s)`, which are given as:\n",
    "\\begin{equation*}\n",
    "R^{V}_N(s) = \n",
    "\\begin{bmatrix}\n",
    "\\hat{v}_{N}(s_{1}) & \\hat{v}_{N}(s_{2}) &  \\cdots  &\\hat{v}_{N}(s_{r})\n",
    "\\end{bmatrix}\n",
    "\\quad \\text{and} \\quad\n",
    "R^{W}_M(s) = \n",
    "\\begin{bmatrix}\n",
    "\\hat{w}_{M}(s_{1}) & \\hat{w}_{M}(s_{2}) & \\cdots & \\hat{w}_{M}(s_{r})\n",
    "\\end{bmatrix},\n",
    "\\end{equation*}\n",
    "where $\\hat{v}_{N}(s_{i})\\in\\mathbb{C}^{n\\times 1}$ and $\\hat{w}_{M}(s_{i})\\in\\mathbb{C}^{n\\times 1}$ are the reconstructed solutions of the reduced solutions $v_{N}(s_{i})\\in\\mathbb{C}^{N\\times 1}$ and $w_{M}(s_{i})\\in\\mathbb{C}^{M\\times 1}$ with reduction orders $N$ and $M$, respectively, for the following (parameter-separable) parameterized linear coercive models (FOM) evaluated at a given parameter $s_{i}$.\n",
    "\\begin{align*}\n",
    "    a_{1}(v, u; s) = l_{1}(u) \\quad v, u\\in \\mathbb{C}^{n\\times 1}\\\\\n",
    "    a_{2}(w, u; s) = l_{2}(u) \\quad w, u\\in \\mathbb{C}^{n\\times 1}\n",
    "\\end{align*}\n",
    "where $a_{1}(v, u; s) = u^{*}(sI_{n} - A)v\\in \\mathbb{C}$ and $l_{1}(u) = u^{*}B$, and $a_{2}(w, u; s) = u^{*}(sI_{n} - A)^{*}w\\in \\mathbb{C}$ and $l_{2}(u) = u^{*}C^{T}$, and solutions to these parametrized linear coercive models are\n",
    "\\begin{equation*}\n",
    "    v(s) = (sI_{n} - A)^{-1}B \\quad \\text{and} \\quad w(s) = (sI_{n} - A)^{-*}C^{T}.\n",
    "\\end{equation*}\n",
    "Consider some initial interpolation data $-\\mu_{i}, \\hat{c}_{i}, \\hat{b}_{i}\\in\\mathbb{C}$ for $0 < r \\leq n$. Therefore, the POD-projection matrices are given by\n",
    "\\begin{equation*}\n",
    "    V_{POD}= \n",
    "    \\begin{bmatrix}\n",
    "    \\hat{v}_{N}(-\\mu_{1})\\hat{b}_{1}&\\hat{v}_{N}(-\\mu_{2})\\hat{b}_{2}&\\cdots&\\hat{v}_{N}(-\\mu_{r})\\hat{b}_{r}\n",
    "    \\end{bmatrix} = R^{V}_N(\\mu)D_{\\hat{b}} \\quad \\text{and} \\quad\n",
    "    W_{POD} = \n",
    "    \\begin{bmatrix}\n",
    "    \\hat{w}_{N}(-\\mu_{1})\\hat{c}_{1}&\\hat{w}_{N}(-\\mu_{2})\\hat{c}_{2}&\\cdots&\\hat{w}_{N}(-\\mu_{r})\\hat{c}_{r}\n",
    "    \\end{bmatrix} = R^{W}_M(\\mu)D_{\\hat{c}},\n",
    "\\end{equation*}\n",
    "where $\\mu = (-\\mu_{1}, -\\mu_{2},\\ldots, -\\mu_{r})$ and \n",
    "\\begin{equation*}\n",
    "    D_{\\hat{b}} = diag(\\hat{b}_{1}, \\hat{b}_{2}, \\ldots, \\hat{b}_{r}) \\quad \\text{and} \\quad D_{\\hat{c}} = diag(\\hat{c}_{1}, \\hat{c}_{2}, \\ldots, \\hat{c}_{r}).\n",
    "\\end{equation*}   \n",
    "This observation provides us with a fairly good error estimate for the projection matrices.\n",
    "\\begin{align*}\n",
    "    \\lVert V - V_{POD}\\rVert &= \\lVert R^{V}(\\mu)D_{\\hat{b}} - R^{V}_N(\\mu)D_{\\hat{b}}\\rVert = \\lVert (R^{V}(\\mu) - R^{V}_N(\\mu))D_{\\hat{b}}\\rVert \\leq \\lVert D_{\\hat{b}}\\rVert \\cdot \\lVert R^{V}(\\mu) - R^{V}_N(\\mu)\\rVert,\\\\\n",
    "    \\lVert W - W_{POD}\\rVert &= \\lVert R^{W}(\\mu)D_{\\hat{c}} - R^{W}_M(\\mu)D_{\\hat{c}}\\rVert = \\lVert (R^{W}(\\mu) - R^{W}_M(\\mu))D_{\\hat{c}}\\rVert \\leq \\lVert D_{\\hat{c}}\\rVert \\cdot \\lVert R^{W}(\\mu) - R^{W}_M(\\mu)\\rVert.\n",
    "\\end{align*}  \n",
    "This demonstrates that if $\\lVert R^{V}(\\mu) - R^{V}_N(\\mu) \\rVert$ and $\\lVert R^{W}(\\mu) - R^{W}_M(\\mu) \\rVert \\to 0$ as $N, M \\to n$, then $\\lVert V - V_{POD} \\rVert$ and $\\lVert W - W_{POD} \\rVert\\to 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProjectionMatrices(pod_rom_V, pod_reductor_V, pod_rom_W, pod_reductor_W, mu, b, c, biorth = None, numpy = None):\n",
    "\n",
    "    '''\n",
    "    Inputs:\n",
    "    ------------------------------------------------\n",
    "    pod_rom_V\n",
    "    pod_rom_W\n",
    "    pod_reductor_V\n",
    "    pod_reductor_W\n",
    "    mu - list of -mu_i values -> type(mu[i]) = pymor.parameters.base.Mu (list of Mu objects)\n",
    "    b - NumPy array -> b.shape = (r,) where r = len(mu)\n",
    "    c - NumPy array -> c.shape = (r,) where r = len(mu)\n",
    "    validation_set - an array containing parameters used to evaluate the reduced model after its construction -> type(validation_set[i]) = pymor.parameters.base.Mu (list of Mu objects)\n",
    "    ------------------------------------------------\n",
    "    Outputs: Biorthonormal pair of projection matrices V, W using biorthonormal Gram-Schmidt process\n",
    "    ------------------------------------------------\n",
    "    V - projection matrix V -> NumpyVectorArray -> V.shape = (n, r)\n",
    "    W - projection matrix W -> NumpyVectorArray -> W.shape = (n, r)\n",
    "    '''\n",
    "    \n",
    "    # Solution arrays containing len(validation_set) many reduced samples\n",
    "    card_mu = len(mu)\n",
    "    reduced_solution_V = pod_rom_V.solution_space.empty()\n",
    "    reduced_solution_W = pod_rom_W.solution_space.empty()\n",
    "    for s in mu:\n",
    "        reduced_solution_V.append(pod_rom_V.solve(s))\n",
    "        reduced_solution_W.append(pod_rom_W.solve(s))\n",
    "        \n",
    "    # It would be better to get matrices where columns are the reconstructed reduced solutions as in theory we will use such matrix; however PyMor only has vstack option (appending as a row of a matrix)\n",
    "    reduced_solution_reconstruct_V_T = pod_reductor_V.reconstruct(reduced_solution_V) # a matrix with rows representing the reconstructed reduced solutions for different parameter values to first parametrized coercive model (row i will give us (s_{i}I - A)^{-1}B)\n",
    "    reduced_solution_reconstruct_W_T = pod_reductor_W.reconstruct(reduced_solution_W) # a matrix with rows representing the reconstructed reduced solutions for different parameter values to second parametrized coercive model (row i will give us (s_{i}I - A)^{-*}C^T)\n",
    "\n",
    "    # To align with the theory, we take the transpose of the result. Also, note that the transpose operation does not exist in PyMor for `NumpyVectorArray`, so we first take the transpose of the NumPy array and then convert it back\n",
    "    space_V_numpy = NumpyVectorSpace(card_mu)\n",
    "    space_W_numpy = NumpyVectorSpace(card_mu)\n",
    "    R_V = space_V_numpy.make_array(reduced_solution_reconstruct_V_T.to_numpy().T)\n",
    "    R_W = space_W_numpy.make_array(reduced_solution_reconstruct_W_T.to_numpy().T)\n",
    "\n",
    "    R_V, R_W = R_V.to_numpy(), R_W.to_numpy() # Note: One may also use R_V.impl._array to get np.ndarray type needed for computation\n",
    "    D_b, D_c = np.diag(b), np.diag(c)\n",
    "\n",
    "    V_numpy = np.matmul(R_V, D_b)\n",
    "    W_numpy = np.matmul(R_W, D_c)\n",
    "\n",
    "    if biorth is True:\n",
    "        space = NumpyVectorSpace(V_numpy.shape[0])\n",
    "        V = space.make_array(V_numpy.T)\n",
    "        W = space.make_array(W_numpy.T)\n",
    "        [V_bi, W_bi] = gram_schmidt_biorth(V, W, check_tol = 10**(-8)) # NumpyVectorArray\n",
    "        if numpy is True:\n",
    "            return [V_bi.to_numpy().T, W_bi.to_numpy().T]\n",
    "        else:\n",
    "            return [V_bi, W_bi]       \n",
    "    else:\n",
    "        if numpy is True:\n",
    "            return [V_numpy, W_numpy]\n",
    "        else:\n",
    "            space = NumpyVectorSpace(V_numpy.shape[1])\n",
    "            V = space.make_array(V_numpy)\n",
    "            W = space.make_array(W_numpy)\n",
    "            return [V, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(A, B, C, mu, b, c, V_pod, W_pod, norm, biorth = None):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "    ------------------------------------------------\n",
    "    A - matrix -> NumPy array or NumpyMatrixOperator -> A.shape = (n, n)\n",
    "    B - (column) vector -> NumPy array or NumpyMatrixOperator -> B.shape = (n, 1)\n",
    "    C - (row) vector -> NumPy array or NumpyMatrixOperator -> C.shape = (1, n)\n",
    "    mu - list of -mu_i values -> type(mu[i]) = pymor.parameters.base.Mu (list of Mu objects)\n",
    "    b - NumPy array -> b.shape = (r,) where r = len(mu)\n",
    "    c - NumPy array -> c.shape = (r,) where r = len(mu)\n",
    "    V_pod - POD-projection matrix V -> NumpyVectorArray -> V.shape = (n, r)\n",
    "    W_pod - POD-projection matrix W -> NumpyVectorArray -> V.shape = (n, r)\n",
    "    norm - see 'https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html' for eight different matrix norms\n",
    "    ------------------------------------------------\n",
    "    Output:\n",
    "    ------------------------------------------------\n",
    "    error - [||V_exact - V_POD||_{norm}, ||W_exact - W_POD||_{norm}] -> list of floats\n",
    "    '''\n",
    "    \n",
    "    dim = A.shape[0] if isinstance(A, np.ndarray) else to_matrix(A).shape[0]\n",
    "    \n",
    "    # NumPy convertions\n",
    "    A = A if isinstance(A, np.ndarray) else to_matrix(A).toarray()\n",
    "    B = B if isinstance(B, np.ndarray) else to_matrix(B)\n",
    "    C = C if isinstance(C, np.ndarray) else to_matrix(C)\n",
    "    mu_values = np.array([s['s'] for s in mu]) \n",
    "    \n",
    "    if isinstance(V_pod, np.ndarray) is False:\n",
    "        V_pod_numpy = V_pod.to_numpy()\n",
    "    else:\n",
    "        V_pod_numpy = V_pod\n",
    "    if isinstance(W_pod, np.ndarray) is False:\n",
    "        W_pod_numpy = W_pod.to_numpy()\n",
    "    else:\n",
    "        W_pod_numpy = W_pod\n",
    "    \n",
    "    # Exact projection matrices\n",
    "    identity = np.eye(dim)\n",
    "    D_b, D_c = np.diag(b), np.diag(c)\n",
    "    \n",
    "    V_exact = np.matmul(np.hstack([np.matmul(np.linalg.inv(s*identity - A), B) for s in mu_values]), D_b)\n",
    "    W_exact = np.matmul(np.hstack([(np.matmul(np.conjugate(np.linalg.inv(s*identity - A).T), C.T)) for s in mu_values]), D_c)\n",
    "\n",
    "    if biorth is True:\n",
    "        space = NumpyVectorSpace(V_exact.shape[0])\n",
    "        V = space.make_array(V_exact.T)\n",
    "        W = space.make_array(W_exact.T)\n",
    "        [V_bi, W_bi] = gram_schmidt_biorth(V, W, check_tol = 10**(-8))\n",
    "        V_exact = V_bi.to_numpy().T\n",
    "        W_exact = W_bi.to_numpy().T\n",
    "\n",
    "    # Computing error norms\n",
    "    error_V = np.linalg.norm(V_exact - V_pod_numpy, norm)\n",
    "    error_W = np.linalg.norm(W_exact - W_pod_numpy, norm)\n",
    "\n",
    "    return [error_V, error_W]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1225a86042d947f99fe77711446a3a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(HTML(value='', layout=Layout(height='16em', width='100%')),), titles=('Log Output',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pymor.models.examples import penzl_example\n",
    "\n",
    "penzl = penzl_example()\n",
    "\n",
    "A = penzl.A\n",
    "B = penzl.B\n",
    "C = penzl.C\n",
    "\n",
    "# Create Matrix induced Stationary Models\n",
    "[model_penzl_V, model_penzl_W] = MatrixModel(penzl.A, penzl.B, penzl.C)\n",
    "\n",
    "# Define a parameter space\n",
    "parameter_space = model_penzl_V.parameters.space(0.01, 10.)\n",
    "\n",
    "# Create POD-Galerkin RB reductors\n",
    "training_set = parameter_space.sample_randomly(30)\n",
    "[pod_rom_V, pod_reductor_V, pod_rom_W, pod_reductor_W] = MatrixReductor(model_penzl_V, model_penzl_W, training_set, reduced_order_V = 20, reduced_order_W = 20)\n",
    "\n",
    "# Find projection matrices V, W\n",
    "b = np.random.rand(100)\n",
    "c = np.random.rand(100)\n",
    "mu = parameter_space.sample_randomly(100)\n",
    "[V, W] = ProjectionMatrices(pod_rom_V = pod_rom_V, pod_reductor_V = pod_reductor_V, pod_rom_W = pod_rom_W, pod_reductor_W = pod_reductor_W, mu = mu, b = b, c = c, numpy = True)\n",
    "[V_bi, W_bi] = ProjectionMatrices(pod_rom_V = pod_rom_V, pod_reductor_V = pod_reductor_V, pod_rom_W = pod_rom_W, pod_reductor_W = pod_reductor_W, mu = mu, b = b, c = c, numpy = True, biorth = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The diagonal entries of W^TV is \n",
      " [2.87937836e-01 1.07297839e-02 1.79050308e-02 1.26912469e-01\n",
      " 3.64502039e-02 2.55741596e-02 1.96167575e-03 3.15698704e-02\n",
      " 1.73619387e-02 4.74775877e-02 6.29967180e-02 1.07675377e-02\n",
      " 1.37631855e-01 4.32501757e-02 1.16889393e-01 6.39801743e-01\n",
      " 4.89819415e-03 3.60855284e-02 1.98453227e-03 2.79937202e-02\n",
      " 3.72932894e-04 7.99645421e-03 9.69102990e-03 1.09136495e-02\n",
      " 7.97025203e-02 3.88520740e-03 2.00587138e-02 3.29471322e-02\n",
      " 3.87943072e-03 6.83594004e-02 5.73901807e-02 1.26258147e-01\n",
      " 3.95192259e-01 6.55322482e-02 3.00426640e-01 1.54664965e-01\n",
      " 5.39945469e-03 2.91072390e-02 3.14967313e-01 1.54715215e-01\n",
      " 5.43154576e-03 2.09740147e-02 1.50584569e-02 6.93064007e-02\n",
      " 2.00305811e-02 6.74713710e-02 3.23574789e-01 8.01598813e-02\n",
      " 3.09694926e-01 1.00724751e-02 3.48597223e-02 6.79542386e-03\n",
      " 3.44705029e-01 5.50141064e-02 9.88422394e-03 2.48188702e-02\n",
      " 4.21690009e-03 9.80242260e-02 8.10429047e-03 2.79840902e-02\n",
      " 1.81232154e-01 1.06075879e-02 8.39731194e-03 3.91939174e-03\n",
      " 7.20274357e-02 1.73534275e-02 3.30600193e-01 2.98495220e-03\n",
      " 2.97419746e-02 2.97897230e-01 2.30660372e-01 1.03860405e-01\n",
      " 3.99622205e-02 1.57810126e-03 5.62095038e-02 2.94322422e-02\n",
      " 7.75625405e-02 2.86682737e-02 9.99302837e-01 2.00985783e-01\n",
      " 5.47315921e-04 1.29386254e-02 1.71183482e-02 1.34008157e-02\n",
      " 1.39346222e-02 3.32176465e-02 1.15630767e-02 1.09246791e-04\n",
      " 9.44594115e-02 5.23373171e-02 6.57292903e-02 4.22782312e-02\n",
      " 1.99643981e-02 7.36091971e-02 2.01920681e-01 5.03121340e-02\n",
      " 2.43641296e-04 4.75148797e-02 4.64042887e-02 4.17350530e-03] \n",
      " and diagonal entries of biorthonormalized W^TV is \n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.].\n"
     ]
    }
   ],
   "source": [
    "diag = np.diag(np.matmul(W.T, V))\n",
    "diag_bi = np.diag(np.matmul(W_bi.T, V_bi))\n",
    "print(f'The diagonal entries of W^TV is \\n {diag} \\n and diagonal entries of biorthonormalized W^TV is \\n {diag_bi}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455f0d5f66f040ee9955453532719d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(HTML(value='', layout=Layout(height='16em', width='100%')),), titles=('Log Output',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linf norm of V - V_POD is 1.8690843144042457e-13 and W - W_POD is 2.1727758481304704e-13.\n",
      "The L2 norm of V - V_POD is 3.015086157364575e-14 and W - W_POD is 3.319540434996445e-14.\n",
      "The Linf norm of V^bi - V^bi_POD is 7404.780079656258 and W^bi - W^bi_POD is 11.746076891631116.\n",
      "The L2 norm of V^bi - V^bi_POD is 16988.256279859612 and W^bi - W^bi_POD is 4.528500696152019.\n"
     ]
    }
   ],
   "source": [
    "# Use error function defined above\n",
    "linf = error(A = A, B = B, C = C, mu = mu, b = b, c = c, V_pod = V, W_pod = W, norm = np.inf)\n",
    "l2 = error(A = A, B = B, C = C, mu = mu, b = b, c = c, V_pod = V, W_pod = W, norm = 2)\n",
    "linf_bi = error(A = A, B = B, C = C, mu = mu, b = b, c = c, V_pod = V_bi, W_pod = W_bi, norm = np.inf, biorth = True)\n",
    "l2_bi = error(A = A, B = B, C = C, mu = mu, b = b, c = c, V_pod = V_bi, W_pod = W_bi, norm = 2, biorth = True)\n",
    "print(f'The Linf norm of V - V_POD is {linf[0]} and W - W_POD is {linf[1]}.')\n",
    "print(f'The L2 norm of V - V_POD is {l2[0]} and W - W_POD is {l2[1]}.')\n",
    "print(f'The Linf norm of V^bi - V^bi_POD is {linf_bi[0]} and W^bi - W^bi_POD is {linf_bi[1]}.')\n",
    "print(f'The L2 norm of V^bi - V^bi_POD is {l2_bi[0]} and W^bi - W^bi_POD is {l2_bi[1]}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mor_lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
