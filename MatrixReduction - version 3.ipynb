{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f243fb99-810c-46f2-8d1c-419c8cecf606",
   "metadata": {},
   "source": [
    "The transfer function for the causal LTI system with a realization $(A, B, C, D)$ is given by\n",
    "\\begin{equation*}\n",
    "    H(s) = C(sI_{n} - A)^{-1}B.\n",
    "\\end{equation*}\n",
    "Notice that $H(s) = Cv(s)$, where $v(s)$ is the solution of a parametrized linear coercive model\n",
    "\\begin{equation}\n",
    "    a(v, w; s) = l(w),\n",
    "\\end{equation}\n",
    "where $a(v, w; s) = w^{*}(sI_{n} - A)v$ and $l(w) = w^{*}B$. In other words, we replace the matrix computation of $(sI_{n} - A)^{-1}B$ with a parametrized model (1). However, if one wants to apply this to the Iterative rational Krylov algorithm (IRKA), then the following matrix computations must be done to construct the projection matrices $V$ and $W$:\n",
    "\\begin{equation*}\n",
    "    (-\\mu_{i}I_{n} - A)^{-1}B\\hat{b}_{i}, \\quad \\text{and} \\quad (-\\mu_{i}I_{n} - A)^{-*}C^{T}\\hat{c}_{i} \\quad \\text{for } i = 1,\\ldots,r,\n",
    "\\end{equation*}\n",
    "where $-\\mu_{i}, \\hat{c}_{i}, \\hat{b}_{i}$ are some initial interpolation data and $0 < r \\leq n$ is the desired order of approximating ROM. So, we have decided to solve two parametrized linear coercive models to construct projection matrices $V$ and $W$:\n",
    "\\begin{equation}\n",
    "    a_{1}(v_{1}, w; s) = l_{1}(w) \\quad \\text{and} \\quad a_{2}(v_{2}, w; s) = l_{2}(w),\n",
    "\\end{equation}\n",
    "where $a_{1}(v_{1}, w; s) = w^{*}(sI_{n} - A)v_{1}$ and $l_{1}(w) = w^{*}B$, and $a_{2}(v_{2}, w; s) = w^{*}(sI_{n} - A)^{*}v_{2}$ and $l_{2}(w) = w^{*}C^{T}$, and solutions to these parametrized linear coercive models are\n",
    "\\begin{equation*}\n",
    "    v_{1}(s) = (sI_{n} - A)^{-1}B \\quad \\text{and} \\quad v_{2}(s) = (sI_{n} - A)^{-*}C^{T}.\n",
    "\\end{equation*}\n",
    "Therefore, knowing $v_{1}(\\mu_{i})$ and $v_{2}(\\mu_{i})$ for $i = 1, \\ldots, r$ will suffice for constructing the projection matrices $V$ and $W$. Also, note that these two FOMs are parameter-separable, i.e.,\n",
    "\\begin{equation*}\n",
    "    a_{1}(v_{1},w;s) = w^{*}(sI_{n} - A)v_{1} = sw^{*}I_{n}v_{1} - w^{*}Av_{1}  \\quad  a_{2}(v_{2},w;s) = w^{*}(sI_{n} - A)^{*}v_{2} = \\overline{s}w^{*}I_{n}v_{2} - w^{*}A^{*}v_{2}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2d1bcb5-cc0e-4fea-857a-a99f7cb1031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "from pymor.basic import *\n",
    "from pymor.models.basic import StationaryModel\n",
    "from pymor.operators.constructions import LincombOperator\n",
    "from pymor.operators.numpy import NumpyMatrixOperator\n",
    "from pymor.parameters.functionals import ProjectionParameterFunctional, ConjugateParameterFunctional\n",
    "from pymor.vectorarrays.numpy import NumpyVectorSpace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6592df60-f621-4eb5-a723-c180b2ba1879",
   "metadata": {},
   "source": [
    "### Constructing a stationary model\n",
    "Let us construct a stationary model of the following parametrized linear coercive model using `pyMOR`:\n",
    "\\begin{equation}\n",
    "    a(v, w; s) = l(w),\n",
    "\\end{equation}\n",
    "where $a(v, w; s) = w^{*}(sI_{n} - A)v$ and $l(w) = w^{*}B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e5a5d02-f4fb-4418-9e71-25a089a3ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatrixModel(A, B):\n",
    "\n",
    "    '''\n",
    "    This function create a stationary model of the following linear coercive model derived for the given two matrices A and B:\n",
    "    \n",
    "        a(v, w; s) =w^{*}(sI_{n} - A)v and l(w) = w^{*}B.\n",
    "    '''\n",
    "\n",
    "    # Define NumpyMatrixOperators\n",
    "    if isinstance(A, np.ndarray) and isinstance(B, np.ndarray):\n",
    "        dim = A.shape[0]\n",
    "        A_op = NumpyMatrixOperator(A)\n",
    "        B_op = NumpyMatrixOperator(B) # B.shape = (-,1) if you consider vector \n",
    "    else:\n",
    "        dim = to_matrix(A).shape[0]\n",
    "        A_op = A\n",
    "        B_op = B \n",
    "\n",
    "    I_op = NumpyMatrixOperator(np.eye(dim))\n",
    "\n",
    "    # Define parameter functional for 's'\n",
    "    s_param = ProjectionParameterFunctional('s', 1)\n",
    "\n",
    "    # Define bilinear form a(v, w; s) = w^* (sI - A)v\n",
    "    a_op = LincombOperator([I_op, A_op], [s_param, -1])\n",
    "\n",
    "    # Define linear functional l(w) = w^*B\n",
    "    l_op = B_op\n",
    "\n",
    "    # Define the StationaryModel\n",
    "    model = StationaryModel(operator = a_op, rhs = l_op)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2815a64-3885-48f9-ba8c-ac4d582a96b2",
   "metadata": {},
   "source": [
    "### Examples\n",
    "Notice that to make this process more convenient, we provide two options for input matrices. If one has the matrices as `NumPy` arrays, they can import them directly without changing their type to work with `pyMOR`. Additionally, if one wants to input matrices from existing `pyMOR` models, this can also be done directly. To demonstrate this, we provide two examples: one with random matrices that we construct ourselves, and the other with matrices imported from the `penzl_example` in `pymor.models.examples`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a187f88-ab03-4c8b-af30-2cb5e9400190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StationaryModel(\n",
       "    LincombOperator(\n",
       "        (NumpyMatrixOperator(<20x20 dense>), NumpyMatrixOperator(<20x20 dense>)),\n",
       "        (ProjectionParameterFunctional('s', index=0), -1)),\n",
       "    NumpyMatrixOperator(<20x1 dense>),\n",
       "    output_functional=ZeroOperator(NumpyVectorSpace(0), NumpyVectorSpace(20)),\n",
       "    products={},\n",
       "    output_d_mu_use_adjoint=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stationary model constructed using random numpy arrays\n",
    "\n",
    "# Randomly generated arrays\n",
    "np.random.seed(127)\n",
    "matrixA = np.random.rand(20, 20) # A is 20x20 matrix\n",
    "matrixB = np.random.rand(20).reshape(20,1) # B is 20x1 vector\n",
    "\n",
    "model_numpy = MatrixModel(A = matrixA, B = matrixB)\n",
    "model_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b936a0a6-c7ce-481f-acb3-2ab87e82799a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c6b13030a14522b4649a86fcb9b8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(HTML(value='', layout=Layout(height='16em', width='100%')),), titles=('Log Output',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution to the linear coercive model is \n",
      " [[ 1.10896524  1.96032033  0.02339715  0.52739001 -0.35238441 -1.85189312\n",
      "  -0.11570617 -0.4575037   0.55493919 -0.96350068  1.01490125  0.05632634\n",
      "   0.23435721 -0.72291187  0.47195613 -1.1582535  -0.48791287  0.20426283\n",
      "  -0.56944887 -0.30429143]].\n",
      "The exact value of the matrix computation (1.4I - A)^{-1}B is \n",
      " [[ 1.10896524  1.96032033  0.02339715  0.52739001 -0.35238441 -1.85189312\n",
      "  -0.11570617 -0.4575037   0.55493919 -0.96350068  1.01490125  0.05632634\n",
      "   0.23435721 -0.72291187  0.47195613 -1.1582535  -0.48791287  0.20426283\n",
      "  -0.56944887 -0.30429143]].\n",
      "The L-infinity error is 2.4424906541753444e-15.\n"
     ]
    }
   ],
   "source": [
    "# Set parameter for evaluation\n",
    "parameter = {'s': 1.4}  # s = 1.4\n",
    "\n",
    "# Solve the model\n",
    "solution = model_numpy.solve(parameter).to_numpy()\n",
    "\n",
    "# Exact matrix computation\n",
    "exact = (inv(parameter['s']*np.eye(20) - matrixA)@matrixB).reshape(1, 20)\n",
    "\n",
    "# A comparison between the model's result and the exact matrix computation\n",
    "print(f'The solution to the linear coercive model is \\n {solution}.')\n",
    "print(f'The exact value of the matrix computation ({parameter[\"s\"]}I - A)^{{-1}}B is \\n {exact}.')\n",
    "print(f'The L-infinity error is {np.max(abs(exact - solution))}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fedee36-5de9-41a0-b802-5df69b135ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StationaryModel(\n",
       "    LincombOperator(\n",
       "        (NumpyMatrixOperator(<1006x1006 dense>), NumpyMatrixOperator(<1006x1006 sparse, 1012 nnz>)),\n",
       "        (ProjectionParameterFunctional('s', index=0), -1)),\n",
       "    NumpyMatrixOperator(<1006x1 dense>),\n",
       "    output_functional=ZeroOperator(NumpyVectorSpace(0), NumpyVectorSpace(1006)),\n",
       "    products={},\n",
       "    output_d_mu_use_adjoint=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stationary model constructed using matrices obtained from penzl example\n",
    "from pymor.models.examples import penzl_example\n",
    "\n",
    "penzl = penzl_example()\n",
    "\n",
    "model_penzl = MatrixModel(penzl.A, penzl.B)\n",
    "model_penzl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e89aa89f-bc33-474a-8676-0c8f844e48a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30a4b3a4922472399d8c970b6464d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(HTML(value='', layout=Layout(height='16em', width='100%')),), titles=('Log Output',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution to the linear coercive model is \n",
      " [[ 0.10004002+2.00080032e-03j -0.10004002+2.00080032e-03j\n",
      "   0.050005  +5.00050005e-04j ...  0.001003  -2.01204612e-06j\n",
      "   0.001002  -2.00801600e-06j  0.001001  -2.00399798e-06j]].\n",
      "The exact value of the matrix computation ((-1+2j)I - A)^{-1}B is \n",
      " [[ 0.10004002+2.00080032e-03j -0.10004002+2.00080032e-03j\n",
      "   0.050005  +5.00050005e-04j ...  0.001003  -2.01204612e-06j\n",
      "   0.001002  -2.00801600e-06j  0.001001  -2.00399798e-06j]].\n",
      "The L-infinity error is 2.7755575615628914e-17.\n"
     ]
    }
   ],
   "source": [
    "from pymor.algorithms.to_matrix import to_matrix\n",
    "\n",
    "# Set parameter for evaluation\n",
    "parameter = {'s': -1 + 2*1j}  # s = - 1 + 2i\n",
    "\n",
    "# Solve the model\n",
    "solution = model_penzl.solve(parameter).to_numpy()\n",
    "\n",
    "# Exact matrix computation\n",
    "matrixA = to_matrix(penzl.A).toarray()\n",
    "matrixB = to_matrix(penzl.B)\n",
    "\n",
    "exact = (inv(parameter['s']*np.eye(penzl.order) - matrixA)@matrixB).reshape(1, penzl.order)\n",
    "\n",
    "# A comparison between the model's result and the exact matrix computation\n",
    "print(f'The solution to the linear coercive model is \\n {solution}.')\n",
    "print(f'The exact value of the matrix computation ({parameter[\"s\"]}I - A)^{{-1}}B is \\n {exact}.')\n",
    "print(f'The L-infinity error is {np.max(abs(exact - solution))}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4524c1-8f04-477e-ae98-8d0833a2d987",
   "metadata": {},
   "source": [
    "## Reduced Basis Methods\n",
    "\n",
    "As an example, we will use `penzl_example` from `pymor.models.examples` to construct a reduced basis using the reduced basis methods available in `pyMOR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d507872-5ef7-45d3-bd79-b41e3d0cff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.models.examples import penzl_example\n",
    "\n",
    "penzl = penzl_example()\n",
    "model_penzl = MatrixModel(penzl.A, penzl.B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698bffee-4de6-4e31-8a3f-52807cd936a1",
   "metadata": {},
   "source": [
    "### POD-Galerkin Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1790e6b-5614-4256-b6dc-af50775d4d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2275e1ae046d47b9a1d0da0cfb514343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(HTML(value='', layout=Layout(height='16em', width='100%')),), titles=('Log Output',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An 1006 by 50 snapshot matrix is \n",
      " [[ 0.10291402  0.10107168  0.10802123 ...  0.10184941  0.10213994\n",
      "   0.10938581]\n",
      " [-0.09690529 -0.09890484 -0.09041703 ... -0.0980795  -0.09776428\n",
      "  -0.08838393]\n",
      " [ 0.0507403   0.05026941  0.05211531 ...  0.05046692  0.05054117\n",
      "   0.05250681]\n",
      " ...\n",
      " [ 0.00099999  0.00100192  0.00099416 ...  0.00100112  0.00100081\n",
      "   0.00099244]\n",
      " [ 0.00099899  0.00100092  0.00099318 ...  0.00100011  0.00099981\n",
      "   0.00099145]\n",
      " [ 0.000998    0.00099992  0.00099219 ...  0.00099912  0.00099881\n",
      "   0.00099047]]\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter space\n",
    "parameter_space = model_penzl.parameters.space(0.01, 10.)\n",
    "\n",
    "# Define a training set\n",
    "training_set = parameter_space.sample_randomly(50)\n",
    "\n",
    "# Compute FOM solutions for the parameters in the training set\n",
    "solution_snapshots = model_penzl.solution_space.empty()\n",
    "for s in training_set:\n",
    "    solution_snapshots.append(model_penzl.solve(s))\n",
    "\n",
    "# Snapshot matrix S\n",
    "snapshot_matrix = solution_snapshots.to_numpy().T\n",
    "print(f'An {snapshot_matrix.shape[0]} by {snapshot_matrix.shape[1]} snapshot matrix is \\n {snapshot_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7156f42-ddfa-408e-844d-d1d8d4c85c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the Singular Value Decomposition (SVD) of the snapshot matrix -> S = UΣV^T\n",
    "U, D, Vt = np.linalg.svd(snapshot_matrix, full_matrices = True) # using 'pod_basis, pod_singular_values = pod(solution_snapshots)' gives wrong result (pod_basis._len != 10 (5 != 10)); that's why we don't use it here. \n",
    "\n",
    "# Activate below to automatically select the number of modes based on the energy criterion\n",
    "## The number of modes m should be chosen based on the energy criterion, which ensures that a sufficient portion of the system's total energy (or variance) is captured by the first m modes.\n",
    "#cumulative_energy = np.cumsum(D**2) / np.sum(D**2)\n",
    "\n",
    "##Select the number of modes m to capture at least 95% of the energy\n",
    "#threshold = 0.95  # 95% of the total energy\n",
    "#m = np.argmax(cumulative_energy >= threshold) + 1\n",
    "\n",
    "m = 20 # this is also a reduction order\n",
    "\n",
    "if m > min(snapshot_matrix.shape):\n",
    "    raise ValueError(\"m cannot exceed the rank of the snapshot matrix.\")\n",
    "\n",
    "# The reduced basis (POD basis)\n",
    "pod_basis_numpy = U[:,:m]\n",
    "print(f'The reduced basis (containing the first {m} left singular vectors (POD modes) of the snapshot matrix as its columns) is \\n {pod_basis_numpy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d4cd6-a81c-4825-86df-ba27c8ae6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.reductors.basic import StationaryRBReductor\n",
    "\n",
    "# Convert NumPy array into VectorArray \n",
    "'''\n",
    "The two lines below are the correct way to convert a NumPy reduced basis array into a VectorArray. However, the 'StationaryRBReductor' raises an error because \n",
    "'pod_basis in model_penzl.solution_space' is set to False. This happens because 'pod_basis.dim' is not equal to 'model_penzl.solution_space.dim'. This is \n",
    "expected since pod_basis.dim equals m (the number of modes, which can vary and is not fixed), whereas model_penzl.solution_space.dim is a fixed integer.\n",
    "'''\n",
    "#space = NumpyVectorSpace(m)\n",
    "#pod_basis = space.make_array(pod_basis_numpy)\n",
    "\n",
    "space = NumpyVectorSpace(model_penzl.order)\n",
    "pod_basis = space.make_array(pod_basis_numpy.T) #This is actually transpose of POD-RB basis\n",
    "\n",
    "# POD-Galerkin RB method\n",
    "pod_reductor = StationaryRBReductor(model_penzl, RB = pod_basis) \n",
    "pod_rom = pod_reductor.reduce()\n",
    "pod_rom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaeba71-9b3d-4120-a2c2-719e91897e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Start timing\n",
    "start_time_reduce = time.time()\n",
    "\n",
    "# Define a parameter space\n",
    "parameter_space = model_penzl.parameters.space(0.01, 10.)\n",
    "\n",
    "# Define a validation set\n",
    "r = 10\n",
    "validation_set = parameter_space.sample_randomly(r)\n",
    "\n",
    "# Solution array containing r many reduced samples\n",
    "reduced_solution = pod_rom.solution_space.empty()\n",
    "for s in validation_set:\n",
    "    reduced_solution.append(pod_rom.solve(s))\n",
    "\n",
    "# End timing\n",
    "end_time_reduce = time.time()\n",
    "\n",
    "# Compute and print the elapsed time\n",
    "elapsed_time_reduce = end_time_reduce - start_time_reduce\n",
    "\n",
    "# Reconstruct high-dimensional vector from reduced vector (necessary for error analysis)\n",
    "reduced_solution_reconstruct = pod_reductor.reconstruct(reduced_solution)\n",
    "\n",
    "print(f'The reconstructed reduced solution matrix (with rows representing the reconstructed reduced solutions for different parameter values) is \\n {reduced_solution_reconstruct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b753586-0ccd-456d-8d6c-528e5b9c98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exact matrix computation\n",
    "\n",
    "# Start timing\n",
    "start_time_exact = time.time()\n",
    "\n",
    "matrixA = to_matrix(penzl.A).toarray()\n",
    "matrixB = to_matrix(penzl.B)\n",
    "\n",
    "# Create a NumPy array containing parameters\n",
    "s_values = np.array([s['s'] for s in validation_set]) \n",
    "\n",
    "# Identity matrix of appropriate size\n",
    "identity = np.eye(penzl.order)\n",
    "\n",
    "exact_solution = np.vstack([(np.linalg.inv(s * identity - matrixA) @ matrixB).flatten() for s in s_values])\n",
    "\n",
    "# End timing\n",
    "end_time_exact = time.time()\n",
    "\n",
    "# Compute and print the elapsed time\n",
    "elapsed_time_exact = end_time_exact - start_time_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee71931-6949-45a9-83b5-95518bea1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Error analysis\n",
    "\n",
    "# Start timing\n",
    "start_time_full = time.time()\n",
    "\n",
    "# FOM solution\n",
    "full_solution = model_penzl.solution_space.empty()\n",
    "for s in validation_set:\n",
    "    full_solution.append(model_penzl.solve(s))\n",
    "    \n",
    "# End timing\n",
    "end_time_full = time.time()\n",
    "\n",
    "# Compute and print the elapsed time\n",
    "elapsed_time_full = end_time_full - start_time_full\n",
    "\n",
    "# Convert FOM solution into NumPy array\n",
    "full_solution_numpy = full_solution.to_numpy()\n",
    "\n",
    "# ROM solution\n",
    "reduced_solution_reconstruct_numpy = reduced_solution_reconstruct.to_numpy()\n",
    "\n",
    "# Norms for each training data - > output is an array\n",
    "error_exact = exact_solution - reduced_solution_reconstruct_numpy\n",
    "error_fom = full_solution_numpy - reduced_solution_reconstruct_numpy\n",
    "num_rows = error_exact.shape[0]\n",
    "linfnorm_exact = np.zeros(num_rows)\n",
    "l2norm_exact = np.zeros(num_rows)\n",
    "linfnorm_fom = np.zeros(num_rows)\n",
    "l2norm_fom = np.zeros(num_rows)\n",
    "for row_number in range(num_rows):\n",
    "    linfnorm_exact[row_number] = np.linalg.norm(error_exact[row_number], np.inf)\n",
    "    l2norm_exact[row_number] = np.linalg.norm(error_exact[row_number], 2)  \n",
    "    linfnorm_fom[row_number] = np.linalg.norm(error_fom[row_number], np.inf)\n",
    "    l2norm_fom[row_number] = np.linalg.norm(error_fom[row_number], 2)  \n",
    "\n",
    "# Printing error results\n",
    "print('-'*20 + ' Look below to check if things are going well '+'-'*30)\n",
    "print(f'[The L-infinity norm] The best is {min(linfnorm_exact)} and worst is {max(linfnorm_exact)}.')\n",
    "print(f'[The L-2 norm] The best is {min(l2norm_exact)} and worst is {max(l2norm_exact)}.')\n",
    "print('-'*20 + ' Linf and L2 norms (array) of error vectors '+'-'*30)\n",
    "print(f'The L-infinity norm of (Exact solution - ROM solution) is {linfnorm_exact}.')\n",
    "print(f'The L-infinity norm of (FOM solution - ROM solution) is {linfnorm_fom}.')\n",
    "print(f'The L-2 norm of (Exact solution - ROM solution) is {l2norm_exact}.')\n",
    "print(f'The L-2 norm of (FOM solution - ROM solution) is {l2norm_fom}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30716b2d-ebc2-4e08-8447-a608587a6fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computational time analysis (execution time analysis)\n",
    "print(f'Total computation time of POD-Galerkin ROM: {elapsed_time_reduce:.10f} seconds.')\n",
    "print(f'Total computation time of FOM: {elapsed_time_full:.10f} seconds.')\n",
    "print(f'Total computation time of Exact: {elapsed_time_exact:.10f} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb7e70-10ec-4dfc-a4ec-d2b1e2cfb632",
   "metadata": {},
   "source": [
    "## Summary of POD-Galerkin Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0f94f-36b2-4ca5-9061-415655e4e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatrixReductor(A, B, training_set, validation_set, reduced_order: int, reconstruct: bool = False):\n",
    "\n",
    "    # Construct Matrix induced StationaryModel\n",
    "    model_penzl = MatrixModel(A, B)\n",
    "\n",
    "    # Compute FOM solutions for the parameters in the training set\n",
    "    solution_snapshots = model_penzl.solution_space.empty()\n",
    "    for s in training_set:\n",
    "        solution_snapshots.append(model_penzl.solve(s))\n",
    "\n",
    "    # Snapshot matrix S\n",
    "    snapshot_matrix = solution_snapshots.to_numpy().T\n",
    "\n",
    "    # Finding the Singular Value Decomposition (SVD) of the snapshot matrix -> S = UΣV^T\n",
    "    U, D, Vt = np.linalg.svd(snapshot_matrix, full_matrices = True)\n",
    "\n",
    "    if reduced_order > min(snapshot_matrix.shape):\n",
    "        raise ValueError(\"'reduced_order' cannot exceed the rank of the snapshot matrix.\")\n",
    "\n",
    "    # The reduced basis (POD basis)\n",
    "    pod_basis_numpy = U[:,:reduced_order]\n",
    "\n",
    "    # Convert NumPy array into VectorArray \n",
    "    space = NumpyVectorSpace(model_penzl.order)\n",
    "    pod_basis = space.make_array(pod_basis_numpy.T) #This is actually transpose of POD-RB basis\n",
    "\n",
    "    # POD-Galerkin RB method\n",
    "    pod_reductor = StationaryRBReductor(model_penzl, RB = pod_basis) \n",
    "    pod_rom = pod_reductor.reduce()\n",
    "\n",
    "    # Solution array containing r many reduced samples\n",
    "    reduced_solution = pod_rom.solution_space.empty()\n",
    "    for s in validation_set:\n",
    "        reduced_solution.append(pod_rom.solve(s))\n",
    "\n",
    "    reduced_solution_reconstruct = pod_reductor.reconstruct(reduced_solution)\n",
    "\n",
    "    if reconstruct is True:\n",
    "        return reduced_solution_reconstruct\n",
    "    else:\n",
    "        return [reduced_solution, pod_reductor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673d8d6-cf7d-41b9-a8a4-3d8b3a5e5738",
   "metadata": {},
   "source": [
    "### Examples (with both real and complex parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90e55c3-391f-474d-ad9b-047969659976",
   "metadata": {},
   "source": [
    "#### Real-valued training and validation set\n",
    "In this subsection, we will examine the Matrix Reduction method using a real-valued training set and validation set for real parameters. As an example, we will use `penzl_example` from `pymor.models.examples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0e3ee-4712-4fac-9cac-8f5be76f54a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.models.examples import penzl_example\n",
    "\n",
    "penzl = penzl_example()\n",
    "model_penzl = MatrixModel(penzl.A, penzl.B)\n",
    "\n",
    "A = penzl.A\n",
    "B = penzl.B\n",
    "parameter_space = model_penzl.parameters.space(0.01, 10.)\n",
    "training_set = parameter_space.sample_randomly(30)\n",
    "validation_set = parameter_space.sample_randomly(10)\n",
    "\n",
    "[reduced_solution, pod_reductor] = MatrixReductor(A, B, training_set, validation_set, reduced_order = 15) # reduced_order must be less than or equal to len(training_set)\n",
    "\n",
    "# Reconstruct high-dimensional vector from reduced vector\n",
    "reduced_solution_reconstruct = pod_reductor.reconstruct(reduced_solution)\n",
    "\n",
    "# One may also get reconstructed vector as 'reduced_solution_reconstruct = MatrixReductor(A, B, dim, training_set, validation_set, reduced_order = 15, reconstruct = True)'\n",
    "\n",
    "# Reconstructed high-dimensional NumPy array (necessary for error analysis)\n",
    "reduced_solution_reconstruct_numpy = reduced_solution_reconstruct.to_numpy()\n",
    "#reduced_solution_reconstruct_numpy\n",
    "reduced_solution_reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c33fc-e9aa-40be-beb8-f2442f88c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting matrices to numpy arrays\n",
    "matrixA = to_matrix(penzl.A).toarray()\n",
    "matrixB = to_matrix(penzl.B)\n",
    "\n",
    "# Create a NumPy array containing parameters\n",
    "s_values = np.array([s['s'] for s in validation_set]) \n",
    "\n",
    "# Identity matrix of appropriate size\n",
    "identity = np.eye(penzl.order)\n",
    "\n",
    "# Exact solution\n",
    "exact_solution = np.vstack([(np.linalg.inv(s * identity - matrixA) @ matrixB).flatten() for s in s_values])\n",
    "\n",
    "# Data for an error plot\n",
    "order_list = np.arange(1, 16)\n",
    "linf_list = np.zeros(15)\n",
    "l2_list = np.zeros(15)\n",
    "for i in range(15):\n",
    "    [reduced_solution, pod_reductor] = MatrixReductor(A, B, training_set, validation_set, reduced_order = i)\n",
    "    reduced_solution_reconstruct = pod_reductor.reconstruct(reduced_solution)\n",
    "    reduced_solution_reconstruct_numpy = reduced_solution_reconstruct.to_numpy()\n",
    "    linf_list[i] = np.linalg.norm(exact_solution - reduced_solution_reconstruct_numpy, np.inf)\n",
    "    l2_list[i] = np.linalg.norm(exact_solution - reduced_solution_reconstruct_numpy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c59c6-bdf9-40f8-b962-21b329d0d019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Error norm plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8), dpi=100)\n",
    "ax.semilogy(order_list[6:], linf_list[6:], label = r\"$L^\\infty$ Norm\", color='red', lw = 0.8, marker = 'x')\n",
    "ax.semilogy(order_list[6:], l2_list[6:], label = r\"$L^2$ Norm\", color='blue', lw = 0.8, marker = 'x')\n",
    "ax.set_title(\"Error norms\")\n",
    "ax.set_xlabel(\"Reduced order\")\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fc9c12-716b-47c0-9866-587966bd264f",
   "metadata": {},
   "source": [
    "#### Complex-valued training and validation set (A Vital Step for IRKA)\n",
    "In this subsection, we will examine the Matrix Reduction method using a complex-valued training set and validation set for complex parameters. For the IRKA method, we need to compute matrices at complex-valued interpolation points, and we will check if it works for complex parameters as well. As an example, we will use `penzl_example` from `pymor.models.examples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4cdd3-1127-4191-bc96-ecb169a3109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.parameters.base import Mu\n",
    "\n",
    "# Create a complex-valued training set\n",
    "card_training_set = 40\n",
    "complex_parameters = 10*np.random.random_sample((card_training_set,)) + 10*1j*np.random.random_sample((card_training_set,))\n",
    "imaginary_training_set = []\n",
    "for i in range(card_training_set):\n",
    "    imaginary_training_set.append(Mu({'s': np.array(complex_parameters[i])}))\n",
    "\n",
    "# Create a complex-valued validation set\n",
    "card_validation_set = 10\n",
    "complex_parameters_validation = 15*np.random.random_sample((card_training_set,)) + 15*1j*np.random.random_sample((card_training_set,))\n",
    "imaginary_validation_set = []\n",
    "for k in range(10):\n",
    "    imaginary_validation_set.append(Mu({'s': np.array(complex_parameters_validation[k])}))\n",
    "print(f'An complex-valued training set is {imaginary_training_set}.')\n",
    "print(f'An complex-valued validation set is {imaginary_validation_set}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82171b89-7d68-46b5-939a-8706b8fc0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.models.examples import penzl_example\n",
    "\n",
    "penzl = penzl_example()\n",
    "model_penzl = MatrixModel(penzl.A, penzl.B)\n",
    "\n",
    "A = penzl.A\n",
    "B = penzl.B\n",
    "\n",
    "# Reduced solution\n",
    "reduced_order = 15\n",
    "[reduced_solution, pod_reductor] = MatrixReductor(A, B, imaginary_training_set, imaginary_validation_set, reduced_order = reduced_order)\n",
    "\n",
    "# Reconstruct high-dimensional vector from reduced vector\n",
    "reduced_solution_reconstruct = pod_reductor.reconstruct(reduced_solution)\n",
    "\n",
    "# Reconstructed high-dimensional NumPy array (necessary for error analysis)\n",
    "reduced_solution_reconstruct_numpy = reduced_solution_reconstruct.to_numpy()\n",
    "#reduced_solution_reconstruct_numpy\n",
    "reduced_solution_reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2912e-f423-4da6-a51c-84e7f3c7fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting matrices to numpy arrays\n",
    "matrixA = to_matrix(penzl.A).toarray()\n",
    "matrixB = to_matrix(penzl.B)\n",
    "\n",
    "# Create a NumPy array containing parameters\n",
    "s_values = np.array([s['s'] for s in imaginary_validation_set]) \n",
    "\n",
    "# Identity matrix of appropriate size\n",
    "identity = np.eye(penzl.order)\n",
    "\n",
    "# Exact solution\n",
    "exact_solution = np.vstack([(np.linalg.inv(s * identity - matrixA) @ matrixB).flatten() for s in s_values])\n",
    "\n",
    "# Data\n",
    "reduced_order_error = 15\n",
    "order_list = np.arange(1, reduced_order_error + 1)\n",
    "linf_list = np.zeros(reduced_order_error)\n",
    "l2_list = np.zeros(reduced_order_error)\n",
    "for i in range(reduced_order_error):\n",
    "    [reduced_solution, pod_reductor] = MatrixReductor(A, B, imaginary_training_set, imaginary_validation_set, reduced_order = i)\n",
    "    reduced_solution_reconstruct = pod_reductor.reconstruct(reduced_solution)\n",
    "    reduced_solution_reconstruct_numpy = reduced_solution_reconstruct.to_numpy()\n",
    "    linf_list[i] = np.linalg.norm(exact_solution - reduced_solution_reconstruct_numpy, np.inf)\n",
    "    l2_list[i] = np.linalg.norm(exact_solution - reduced_solution_reconstruct_numpy, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1516880-6c03-45bc-ba6f-2a0d26017c87",
   "metadata": {},
   "source": [
    "### Hooray!🎉 It also seems to handle complex parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c47b8a-77ca-4ae2-b44a-ce5243cc652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error norm plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8), dpi=100)\n",
    "ax.semilogy(order_list[8:], linf_list[8:], label = r\"$L^\\infty$ Norm\", color='red', lw = 0.8, marker = 'x')\n",
    "ax.semilogy(order_list[8:], l2_list[8:], label = r\"$L^2$ Norm\", color='blue', lw = 0.8, marker = 'x')\n",
    "ax.set_title(\"Error norms\")\n",
    "ax.set_xlabel(\"Reduced order\")\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d3bf6d-ea16-4d91-8a0c-2c0c2b82e3ab",
   "metadata": {},
   "source": [
    "### Implementation of Matrix Reduction to IRKA\n",
    "Consider some initial interpolation data $-\\mu_{i}, \\hat{c}_{i}, \\hat{b}_{i}$ for $0 < r \\leq n$. Here, we construct the projection matrices $V$ and $W$ as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "    V = [(-\\mu_{1}I_{n} - A)^{-1}B\\hat{b}_{1} \\quad (-\\mu_{2}I_{n} - A)^{-1}B\\hat{b}_{2} \\quad \\cdots \\quad (-\\mu_{r}I_{n} - A)^{-1}B\\hat{b}_{r}], \\quad \\text{and} \\quad W = [(-\\mu_{1}I_{n} - A)^{-*}C^{T}\\hat{c}_{1} \\quad (-\\mu_{2}I_{n} - A)^{-*}C^{T}\\hat{c}_{2}\\quad \\cdots \\quad (-\\mu_{r}I_{n} - A)^{-*}C^{T}\\hat{c}_{r}] \\quad \\text{for } i = 1,\\ldots,r,\n",
    "\\end{equation*}\n",
    "where $r$ is the desired order of approximating ROM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653fd380-cbd8-46e3-852d-37ee87a28bda",
   "metadata": {},
   "source": [
    "### Defining Functions for Matrix Reduction in IRKA\n",
    "\n",
    "Here, we will revisit and refine everything we have covered so far. Notice that we have written a `MatrixModel` function and a `MatrixReductor` only for the first linear coercive model. However, we need these functions for both models. Below, we explicitly redefine these functions for both cases. Additionally, we introduce a new function called `ProjectionMatrices`, which provides the projection matrices $V$ and $W$ required for IRKA. This function will streamline the process, making it sufficient to call it directly for use in IRKA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bdf39f6-f0bd-4480-9044-924d86b532da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatrixModel(A, B, C):\n",
    "    '''\n",
    "    This function creates stationary models for the following linear coercive models derived for the given three matrices A, B, and C:\n",
    "    \n",
    "        a_1(v, w; s) = w*(sI_n - A)v and l_1(w) = w*B\n",
    "        a_2(v, w; s) = w*(sI_n - A)*v and l_2(w) = w*C^T.\n",
    "\n",
    "    Inputs:\n",
    "    ------------------------------------------------\n",
    "    A - matrix -> NumPy array or NumpyMatrixOperator\n",
    "    B - matrix (or vector)-> NumPy array or NumpyMatrixOperator\n",
    "    C - matrix -> NumPy array or NumpyMatrixOperator\n",
    "    ------------------------------------------------\n",
    "    Outputs:\n",
    "    ------------------------------------------------\n",
    "    model_V - Stationary Model of linear coercive model w*(sI_n - A)v = w*B -> StationaryModel\n",
    "    model_W - Stationary Model of linear coercive model w*(sI_n - A)*v -> StationaryModel\n",
    "    '''\n",
    "\n",
    "    # Define operators (and also a dimension of a model)\n",
    "    if isinstance(A, np.ndarray):\n",
    "        dim = A.shape[0]\n",
    "        A_op = NumpyMatrixOperator(A)\n",
    "    else:\n",
    "        dim = to_matrix(A).shape[0]\n",
    "        A_op = A\n",
    "\n",
    "    if isinstance(B, np.ndarray):\n",
    "        B_op = NumpyMatrixOperator(B)  # B is a vector here\n",
    "    else:\n",
    "        B_op = B  # Could be a more complex operator\n",
    "\n",
    "    if isinstance(C, np.ndarray):\n",
    "        C_op = NumpyMatrixOperator(C.T)  # C is a matrix, take transpose\n",
    "    else:\n",
    "        C_op = C.H  # C is real, so adjoint is transpose\n",
    "\n",
    "    I_op = NumpyMatrixOperator(np.eye(dim))\n",
    "    \n",
    "    # Define parameter functional for 's'\n",
    "    s_param = ProjectionParameterFunctional('s', 1)\n",
    "\n",
    "    # Define bilinear form a(v, w; s) = w*(sI - A)v\n",
    "    a_op_1 = LincombOperator([I_op, A_op], [s_param, -1])\n",
    "\n",
    "    # Define bilinear form a(v, w; s) = w*(sI - A)*v -> Note: (sI - A)* = s*I - A*\n",
    "    a_op_2 = LincombOperator([I_op, AdjointOperator(A_op)], [ConjugateParameterFunctional(s_param), -1])\n",
    "\n",
    "    # Define linear functional l(w) = w^*B\n",
    "    l_op_1 = B_op\n",
    "\n",
    "    # Define linear functional l(w) = w^*C^{T}\n",
    "    l_op_2 = C_op\n",
    "\n",
    "    # Define the StationaryModels\n",
    "    model_V = StationaryModel(operator=a_op_1, rhs=l_op_1)\n",
    "    model_W = StationaryModel(operator=a_op_2, rhs=l_op_2)\n",
    "\n",
    "    return [model_V, model_W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4d7535e-173e-4fc5-931b-6a6a93d75eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatrixReductor(A, B, C, training_set, validation_set, reduced_order_V: int, reduced_order_W: int, reconstruct: bool = False):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "    ------------------------------------------------\n",
    "    A - matrix -> NumPy array or NumpyMatrixOperator\n",
    "    B - matrix -> NumPy array or NumpyMatrixOperator\n",
    "    C - matrix -> NumPy array or NumpyMatrixOperator\n",
    "    training_set - an array containing parameters used to construct the snapshot matrix -> type(training_set[i]) = pymor.parameters.base.Mu (list of Mu objects)\n",
    "    validation_set - an array containing parameters used to evaluate the reduced model after its construction -> type(validation_set[i]) = pymor.parameters.base.Mu (list of Mu objects)\n",
    "    reduced_order_V - order of the reduced model for the first coercive model -> int\n",
    "    reduced_order_W - order of the reduced model for the second coercive model -> int\n",
    "    reconstruct - If 'True', the reconstructed reduced solutions for both coercive models will be output; otherwise, the reduced solutions for both coercive models and the reductors for both reduced models will be returned -> bool\n",
    "    ------------------------------------------------\n",
    "    Outputs:\n",
    "    ------------------------------------------------\n",
    "    reduced_solution_reconstruct_V -> NumpyVectorArray\n",
    "    reduced_solution_reconstruct_W -> NumpyVectorArray\n",
    "    reduced_solution_V -> NumpyVectorArray\n",
    "    reduced_solution_W -> NumpyVectorArray\n",
    "    pod_reductor_V -> StationaryRBReductor\n",
    "    pod_reductor_W -> StationaryRBReductor\n",
    "    '''\n",
    "\n",
    "    # Construct Matrix induced StationaryModels\n",
    "    [model_V, model_W] = MatrixModel(A, B, C, dim = dim)\n",
    "\n",
    "    # Compute FOM solutions for the parameters in the training set\n",
    "    solution_snapshots_V = model_penzl.solution_space.empty()\n",
    "    solution_snapshots_W = model_penzl.solution_space.empty()\n",
    "    for s in training_set:\n",
    "        solution_snapshots_V.append(model_V.solve(s))\n",
    "        solution_snapshots_W.append(model_W.solve(s))\n",
    "        \n",
    "    # Snapshot matrices\n",
    "    snapshot_matrix_V = solution_snapshots_V.to_numpy().T\n",
    "    snapshot_matrix_W = solution_snapshots_W.to_numpy().T\n",
    "\n",
    "    # Finding the Singular Value Decomposition (SVD) of snapshot matrices -> S = UΣV^T\n",
    "    U_V, D_V, Vt_V = np.linalg.svd(snapshot_matrix_V, full_matrices = True)\n",
    "    U_W, D_W, Vt_W = np.linalg.svd(snapshot_matrix_W, full_matrices = True)\n",
    "\n",
    "    if reduced_order_V > min(snapshot_matrix_V.shape):\n",
    "        raise ValueError(\"'reduced_order_V' cannot exceed the rank of the snapshot matrix.\")\n",
    "    if reduced_order_W > min(snapshot_matrix_W.shape):\n",
    "        raise ValueError(\"'reduced_order_W' cannot exceed the rank of the snapshot matrix.\")\n",
    "\n",
    "    # The reduced bases (POD bases)\n",
    "    pod_basis_numpy_V = U_V[:,:reduced_order_V]\n",
    "    pod_basis_numpy_W = U_W[:,:reduced_order_W]\n",
    "\n",
    "    # Convert NumPy array into VectorArray \n",
    "    space_V = NumpyVectorSpace(model_V.order)\n",
    "    space_W = NumpyVectorSpace(model_W.order)\n",
    "    pod_basis_V = space_V.make_array(pod_basis_numpy_V.T) #This is actually transpose of POD-RB basis\n",
    "    pod_basis_W = space_W.make_array(pod_basis_numpy_W.T) #This is actually transpose of POD-RB basis\n",
    "    \n",
    "    # POD-Galerkin RB method\n",
    "    pod_reductor_V = StationaryRBReductor(model_V, RB = pod_basis_V) \n",
    "    pod_reductor_W = StationaryRBReductor(model_W, RB = pod_basis_W) \n",
    "    pod_rom_V = pod_reductor_V.reduce()\n",
    "    pod_rom_W = pod_reductor_W.reduce()\n",
    "\n",
    "    # Solution arrays containing len(validation_set) many reduced samples\n",
    "    reduced_solution_V = pod_rom_V.solution_space.empty()\n",
    "    reduced_solution_W = pod_rom_W.solution_space.empty()\n",
    "    for s in validation_set:\n",
    "        reduced_solution_V.append(pod_rom_V.solve(s))\n",
    "        reduced_solution_W.append(pod_rom_W.solve(s))\n",
    "\n",
    "    reduced_solution_reconstruct_V = pod_reductor_V.reconstruct(reduced_solution_V) # a matrix with rows representing the reconstructed reduced solutions for different parameter values to first parametrized coercive model (row i will give us (s_{i}I - A)^{-1}B)\n",
    "    reduced_solution_reconstruct_W = pod_reductor_W.reconstruct(reduced_solution_W) # a matrix with rows representing the reconstructed reduced solutions for different parameter values to second parametrized coercive model (row i will give us (s_{i}I - A)^{-*}C^T)\n",
    "\n",
    "    if reconstruct is True:\n",
    "        return [reduced_solution_reconstruct_V, reduced_solution_reconstruct_W]\n",
    "    else:\n",
    "        return [reduced_solution_V, reduced_solution_W, pod_reductor_V, pod_reductor_W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0f03ef0-6a2c-4f3c-ac34-913126924c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProjectionMatrices(A, B, C, mu, b, c, training_set, reduced_order_V: int, reduced_order_W: int):\n",
    "\n",
    "    '''\n",
    "    Inputs:\n",
    "    ------------------------------------------------\n",
    "    A - matrix -> NumPy array or NumpyMatrixOperator -> A.shape = (n, n)\n",
    "    B - matrix (or vector) -> NumPy array or NumpyMatrixOperator -> B.shape = (n, m)\n",
    "    C - matrix -> NumPy array or NumpyMatrixOperator -> C.shape = (p, n)\n",
    "    dim - dimension of a full model or number of inputs -> type(dim) = int\n",
    "    mu - list of -mu_i values -> type(mu[i]) = pymor.parameters.base.Mu (list of Mu objects)\n",
    "    b - vector -> b.shape = (m, 1)\n",
    "    c - list of vector -> c.shape = (p, 1)\n",
    "    ------------------------------------------------\n",
    "    Outputs:\n",
    "    ------------------------------------------------\n",
    "    V - projection matrix V -> NumpyVectorArray -> V.shape = (n, r)\n",
    "    W - projection matrix W -> NumpyVectorArray -> W.shape = (n, r)\n",
    "    '''\n",
    "\n",
    "    [V, W] = MatrixReductor(A = A, B = B, C = C, training_set = training_set, validation_set = mu, reduced_order_V = reduced_order_V, reduced_order_W = reduced_order_W, reconstruct = True)\n",
    "\n",
    "    return [V, W] # This actually [V^T, W^T]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
